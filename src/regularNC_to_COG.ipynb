{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "9e4149e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curses import flash\n",
    "import os\n",
    "from pickle import TRUE\n",
    "from re import L\n",
    "import requests\n",
    "import validators\n",
    "import gzip\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import xarray as xa\n",
    "import numpy as np\n",
    "from rio_cogeo import cog_validate\n",
    "import rioxarray\n",
    "\n",
    "# Mapping\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "7e1c64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(input_path):\n",
    "    return xa.open_dataset(input_file_path, engine=\"netcdf4\", decode_coords='all', decode_times=False)\n",
    "\n",
    "def copy_lat_lon_data(file, var_name1, var_name2, var_name3):\n",
    "    lat = file[var_name1].data.copy()\n",
    "#     lat = lat[::-1]\n",
    "    lon = file[var_name2].data.copy()\n",
    "    data = file[var_name3].data[0].copy()\n",
    "    return lat, lon, data\n",
    "\n",
    "def make_new_xarray(lat, lon, data):\n",
    "#     file = xa.Dataset(\n",
    "#         data_vars={\"flash_extent\": ([\"longitude\", \"latitude\"], data)},\n",
    "#         coords={[\"longitude\"]: lon, [\"latitude\"]: lat},\n",
    "#         attrs={\"instrument_ID\": \"NALMA\"}\n",
    "#     )\n",
    "    file = xr.Dataset(\n",
    "        {\n",
    "            \"flash_extent\": ([\"longitude\", \"latitude\"], data),\n",
    "        },\n",
    "        coords={\n",
    "            \"longitude\": ([\"longitude\"], lon),\n",
    "            \"latitude\": ([\"latitude\"], lat),\n",
    "        },\n",
    "    )\n",
    "    return file\n",
    "\n",
    "def generate_cog(file, variable_name, latitude, longitude):\n",
    "    file = file[variable_name]\n",
    "#     file = file[::-1]\n",
    "    file = file.transpose(latitude, longitude)\n",
    "    file.rio.set_spatial_dims(x_dim=longitude, y_dim=latitude, inplace=True)\n",
    "    file.rio.crs\n",
    "    file.rio.set_crs('epsg:4326')\n",
    "    name=f\"S2A_20160724_135032_27XVB_B{random.randint(0,9)}{random.randint(0,9)}{random.randint(0,9)}.tif\"\n",
    "    cog_path=f\"/home/asubedi/test_cog/cogs/{name}\"\n",
    "    print(name)\n",
    "    file.rio.to_raster(rf'{cog_path}', driver='COG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "09e56db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nalma():\n",
    "    input_file_path = \"/home/asubedi/test_cog/NALMA_20230629_235000_600_10src_0.0109deg-dx_flash_extent.nc\"\n",
    "    variable_name = \"flash_extent\"\n",
    "    lat='latitude'\n",
    "    lon='longitude'\n",
    "    return input_file_path, variable_name, lat, lon\n",
    "\n",
    "def wtlma():\n",
    "    input_file_path = \"/home/asubedi/test_cog/WTLMA_20170531_235000_600_10src_0.0108deg-dx_flash_extent.nc\"\n",
    "    variable_name = \"flash_extent\"\n",
    "    lat='latitude'\n",
    "    lon='longitude'\n",
    "    return input_file_path, variable_name, lat, lon\n",
    "\n",
    "def trmm_lis():\n",
    "    input_file_path = '/home/asubedi/Desktop/data/raw-files/TRMM-LIS/lis_vhrfc_1998_2013_v01.nc'\n",
    "    variable_name = \"VHRFC_LIS_FRD\"\n",
    "    lat=\"Latitude\"\n",
    "    lon=\"Longitude\"\n",
    "    return input_file_path, variable_name, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "ad16d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path, variable_name, latitude, longitude = nalma()\n",
    "file = open_file(input_file_path)\n",
    "lat, lon, data = copy_lat_lon_data(file, latitude, longitude, variable_name)\n",
    "file = make_new_xarray(lat, lon ,data)\n",
    "# generate_cog(file, variable_name, latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "0ffef818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 154, lon:-87.13673400878906\n",
      "Index: 155, lon:-87.12581634521484\n",
      "Index: 156, lon:-87.11489868164062\n",
      "Index: 157, lon:-87.1039810180664\n",
      "Index: 158, lon:-87.09306335449219\n",
      "Index: 159, lon:-87.08214569091797\n",
      "--------------------------------------\n",
      "Index: 79, lat: 33.633785247802734\n",
      "Index: 80, lat: 33.642799377441406\n",
      "Index: 81, lat: 33.65181350708008\n",
      "Index: 82, lat: 33.66082763671875\n",
      "Index: 83, lat: 33.66984176635742\n",
      "Index: 84, lat: 33.678855895996094\n",
      "Index: 85, lat: 33.687870025634766\n",
      "Index: 86, lat: 33.69688415527344\n",
      "Index: 88, lat: 33.71491241455078\n",
      "Index: 89, lat: 33.72392654418945\n",
      "Index: 90, lat: 33.732940673828125\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for arr in data:\n",
    "    if np.any(arr != 0) == True:\n",
    "        print(f\"Index: {index}, lon:{lon[index]}\")\n",
    "    index += 1\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "    \n",
    "index = 0\n",
    "for column in data.T:\n",
    "    if np.any(column != 0) == True:\n",
    "        print(f\"Index: {index}, lat: {lat[index]}\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "49de1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_row_col(lat, lon, data):\n",
    "    #finding row with all zeroes    \n",
    "    zero_row = np.where(np.all(data == 0, axis=1))[0]\n",
    "    #removing lon with all zeroes\n",
    "    lon = np.delete(lon, zero_row)\n",
    "    # Find rows with non-zero elements\n",
    "    non_zero_rows = np.any(data != 0, axis=1)\n",
    "    # Filter the array based on non-zero rows\n",
    "    data = data[non_zero_rows]\n",
    "    \n",
    "    #finding columns with all zeroes\n",
    "    zero_columns = np.where(np.all(data == 0, axis=0))[0]\n",
    "    #removing lat with all zeroes\n",
    "    lat = np.delete(lat, zero_columns)\n",
    "    lat = lat[::-1]\n",
    "    # Find rows with non-zero elements\n",
    "    non_zero_rows = np.any(data != 0, axis=1)\n",
    "    # Find columns with non-zero elements\n",
    "    non_zero_columns = np.any(data != 0, axis=0)\n",
    "    # Filter the array based on non-zero rows and columns\n",
    "    data = data[non_zero_rows][:, non_zero_columns]\n",
    "    return lat, lon, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "14856c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, data = delete_row_col(lat, lon, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "f2fbc7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 6 (6, 11)\n"
     ]
    }
   ],
   "source": [
    "print(len(lat), len(lon), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "1aa00bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = make_new_xarray(lat, lon, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "4893e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_netcdf(\"/mnt/c/Users/asubedi/Desktop/testing_nalma_new_array.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "e73365fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_20160724_135032_27XVB_B817.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: /home/asubedi/miniconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n",
      "ERROR 1: PROJ: proj_create_from_name: /home/asubedi/miniconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n",
      "ERROR 1: PROJ: proj_create_from_database: /home/asubedi/miniconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n",
      "Warning 1: PROJ: proj_create_from_database: /home/asubedi/miniconda3/share/proj/proj.db lacks DATABASE.LAYOUT.VERSION.MAJOR / DATABASE.LAYOUT.VERSION.MINOR metadata. It comes from another PROJ installation.\n"
     ]
    }
   ],
   "source": [
    "generate_cog(file, variable_name, latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187743b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
